A[i,] <- cumsum(A[i,])
}
# with(d, plot(p, cumsum(e) / n, type = "l", ylim = c(min(A), max(A))))
# for(i in 1:50){
# lines(d$p, A[i,], type = "l", col = "gray")
# }
# with(d, lines(p, cumsum(e) / n))
pvalues[j] <- mean(apply(A, 1, function(i) max(abs(i)) > supW))
}
library(rms)
rms::residuals
residuals.lrm
lrm(Y~x, data = d)
?lrm
x <- runif(1000)
y <- rbinom(1000, 1, x)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
m2 <- beta_calibration(p1, y, "abm")
p2 <- beta_predict(p1, m2)
calibration(y, p2)
m2 <- beta_calibration(p1, y, "abm")
install.packages("betacalibration")
install.packages("betacal")
library(betacal)
library(tidyverse)
m2 <- beta_calibration(p1, y, "abm")
p2 <- beta_predict(p1, m2)
calibration(y, p2)
calibration(y, p2[,2])
head(p2)
calibration(y, p2)
length(y)
length(p22)
length(p2)
calibration(d_test$y, p2)
length(p1)
m2 <- beta_calibration(p1, d_test$y, "abm")
p2 <- beta_predict(p1, m2)
calibration(d_test$y, p2)
calibration(d_test$y, p1)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
m2 <- beta_calibration(p1, d_test$y, "abm")
p2 <- beta_predict(p1, m2)
calibration(d_test$y, p2)
m2 <- beta_calibration(predict(m, type = "response"), d_train$y, "abm")
# m2 <- beta_calibration(p1, d_test$y, "abm")
p2 <- beta_predict(p1, m2)
calibration(d_test$y, p2)
calibration(d_test$y, p1)
calibration(d_test$y, p2)
x <- runif(1000)
y <- rbinom(1000, 1, x)
d <- data.frame(x = x, y = y)
d_train <- d[1:800,]
d_test <- d[801:1000,]
m <- glm(y~x,family="binomial", data = d_train)
p1 <- predict(m, newdata = d_test, type = "response")
calibration(d_test$y, p1)
m2 <- beta_calibration(predict(m, type = "response"), d_train$y, "abm")
# m2 <- beta_calibration(p1, d_test$y, "abm")
p2 <- beta_predict(p1, m2)
calibration(d_test$y, p2)
calibration(d_test$y, p1)
install.packages("caTools")    # For Logistic regression
install.packages("ROCR")       # For ROC curve to evaluate model
# Loading package
library(caTools)
library(ROCR)
# Splitting dataset
split <- sample.split(mtcars, SplitRatio = 0.8)
split
train_reg <- subset(mtcars, split == "TRUE")
test_reg <- subset(mtcars, split == "FALSE")
# Training model
logistic_model <- glm(vs ~ wt + disp,
data = train_reg,
family = "binomial")
logistic_model
calibration(test_reg$vs, predict(logistic_model, newdata = test_reg, type = "response"))
install.packages("randomForest")  # For implementing random forest algorithm
# Loading package
library(caTools)
library(randomForest)
# Splitting data in train and test data
split <- sample.split(iris, SplitRatio = 0.7)
split
train <- subset(iris, split == "TRUE")
test <- subset(iris, split == "FALSE")
head(train)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = train[-5],
y = train$Species,
ntree = 500)
str(train)
predict(classifier_RF)
predict(classifier_RF, type = "prob")
p_setosa <- predict(classifier_RF, type = "prob")[,1]
p_setosa <- predict(classifier_RF, newdata = test, type = "prob")[,1]
calibration(test$Species == "setosa", p_setosa)
length(p_setosa)
nrow(test)
p_setosa
calibration(test$Species == "setosa", p_setosa)
calibration <- function(y, p, n = 10000, ...){
d <- data.frame(y = y, p = p) %>% arrange(p) %>% mutate(e = y - p, V = p*(1-p)/nrow(d)^2, W = cumsum(e) / nrow(d))
supW <- with(d, max(abs(W)))
n_timepoints <- length(p)
A <- matrix(rnorm(n*n_timepoints), nrow = n, ncol = n_timepoints)
for(i in 1:n_timepoints){
A[,i] <- A[,i] * sqrt(d$V[i])
}
for(i in 1:n){
A[i,] <- cumsum(A[i,])
}
pvalue <- mean(apply(A, 1, function(i) max(abs(i)) > supW))
options(scipen=999)
with(d, plot(p, W * 100, type = "l",
ylim = c(-max(max(abs(A[1:50,])), max(abs(d$W))) * 100, max(max(abs(A[1:50,])), max(abs(d$W))) * 100),
las = 1, xlab = "Estimated probability", ylab = "Cumulative residual", lwd = 2, axes=F,#bty = "n",
main = "Calibration test", xlim = c(0,1), ...))
axis(1,lwd=2)
axis(2,lwd=2, las = 1)
legend("bottomleft", legend = paste0("pvalue = ", round(pvalue, 3)), bty = "n", cex = 1.5)
legend("topleft", legend = c("Realized", "Simulated"), col = c("black", "gray"), bty = "n", pch = "-", cex = 1.5, lwd = 5)
for(i in 1:50){
lines(d$p, A[i,] * 100, type = "l", col = "gray")
}
with(d, lines(p, W * 100, lwd = 2))
}
calibration(test$Species == "setosa", p_setosa)
str(test)
p_versicolor <- predict(classifier_RF, newdata = test, type = "prob")[,2]
calibration(test$Species == "versicolor", p_setosa)
p_versicolor
library(stringr)
# English
d <- words::words
words <- tolower(d[,1])
install.packages("words")
# English
d <- words::words
words <- tolower(d[,1])
mysubset <- function(d, size = 5, notin = NULL, contains = NULL, known = NULL, pos = NULL, bestWord = FALSE){
words <- d[nchar(d) == size]
words <- d <- words[!unlist(if(length(words) != 0) lapply(strsplit(words, ""), function(i) any(i %in% c("-", " ", "/", ".") )) else character(0))]
if(!is.null(notin) & !is.null(contains)) notin <- paste(setdiff(strsplit(notin, "")[[1]], strsplit(contains, "")[[1]]), collapse = "")
if(!is.null(notin)){
notin <- strsplit(notin, "")[[1]]
for(i in 1:length(notin)){
words <- words[!str_detect(words, notin[i])]
}
}
if(!is.null(contains) && !identical(contains, "")){
contains <- strsplit(contains, "")[[1]]
known <- as.numeric(strsplit(known, "")[[1]])
pos <- as.numeric(strsplit(pos, "")[[1]])
if(length(contains) != length(known) | length(known) != length(pos)){
warning("contains, known, and pos must have equal length")
}
for(i in 1:length(contains)){
if(known[i]){
words <- words[substr(words, pos[i], pos[i]) == contains[i]]
}
else{
words <- words[substr(words, pos[i], pos[i]) != contains[i]]
words <- words[str_detect(words, contains[i])]
}
}
}
cat("Number of words:", length(words), "\n")
# test <- if(length(words) != 0) lapply(strsplit(words, ""), function(i) length(unique(i))) == length else F
if(bestWord){
howmany <- rep(NA, length(words))
for(i in 1:length(words)){
howmany[i] <- checkword(words[i], words)
}
most <- which(howmany == max(howmany))
test <- if(length(most) != 0) lapply(strsplit(words[most], ""), function(i) length(unique(i))) == size else F
# cat("Word:", ifelse(any(test == 1), words[match(1, test)], words[1]), "\n")
if(any(test == 1)){
cat("Words:", sample(words[most[which(test == 1)]], 1), "\n")
}
else{
cat("Words:", sample(words[most], 1), "\n")
}
# cat("Word:", ifelse(any(test == 1), words[most[which(test == 1)]], words[most]), "\n")
}
if(!is.null(known) && !identical(known, "")){
if(length(unique(pos[known == 1])) == (size - 1) & length(words) >= 3){
subwords <- strsplit(words, "")
tmp <- rep(NA, length(words))
for(i in 1:length(words)) tmp[i] <- subwords[[i]][!((1:size) %in% pos[known == 1])]
dsub <- d[!(d %in% words)]
for(i in 1:(size-1)){
position <- unique(pos[known == 1])[i]
dsub <- dsub[substr(dsub, position, position) != unique(substr(words, position, position))]
}
howmany <- rep(NA, length(dsub))
for(i in 1:length(dsub)){
howmany[i] <- checkword(dsub[i], tmp)
}
most <- which(howmany == max(howmany))
test <- if(length(most) != 0) lapply(strsplit(dsub[most], ""), function(i) length(unique(i))) == size else F
# cat("Word:", ifelse(any(test == 1), words[match(1, test)], words[1]), "\n")
if(any(test == 1)){
cat("Words:", sample(dsub[most[which(test == 1)]], 1), "\n")
}
else{
cat("Words:", sample(dsub[most],1), "\n")
}
}
}
correct <- readline(prompt = "Correct? ")
if(!as.logical(correct)){
notinAdd <- readline(prompt = "notin? ")
containsAdd <- readline(prompt = "contains? ")
knownAdd <- readline(prompt = "known? ")
posAdd <- readline(prompt = "pos? ")
notin <- paste(c(notin, notinAdd), collapse = "")
contains <- paste(c(contains, containsAdd), collapse = "")
known <- paste(c(known, knownAdd), collapse = "")
pos <- paste(c(pos, posAdd), collapse = "")
mysubset(words, size = size, notin = notin, contains = contains, known = known, pos = pos, bestWord = TRUE)
}
else{
cat("You're welcome!")
}
# cat("Words: ", words[1:5], "\n")
}
checkword <- function(word, dictionary){
word <- paste0("(", paste0(strsplit(word, "")[[1]], collapse = ")|("), ")")
sum(grepl(word, dictionary))
}
mysubset(words, size = 5, bestWord = FALSE)
?ks.test
ks.test
getAnywhere(ks.tst)
getAnywhere(ks.test)
stats::ks.test
getAnywhere(stats::ks.test)
update.packages(ask=F)
rm(list=ls())
set.seed(13072020)
# library(rstudioapi)
library(data.table)
# library(haven)
library(tidyverse)
library(survival)
library(doRNG)
library(doParallel)
cl <- parallel::makeCluster(30)
doParallel::registerDoParallel(cl)
# setwd(dirname(getSourceEditorContext()$path))
# setwd("ucph/hdir/SundKonsolidering_BioStatHome/Documents/")
source("functions.R")
cl <- parallel::makeCluster(1)
cl <- parallel::makeCluster(30)
doParallel::registerDoParallel(cl)
setwd(dirname(getSourceEditorContext()$path))
library(rstudioapi)
setwd(dirname(getSourceEditorContext()$path))
rm(list=ls())
set.seed(13072020)
# library(rstudioapi)
library(data.table)
# library(haven)
library(tidyverse)
library(survival)
library(doRNG)
library(doParallel)
cl <- parallel::makeCluster(6)
doParallel::registerDoParallel(cl)
setwd(dirname(getSourceEditorContext()$path))
# setwd("ucph/hdir/SundKonsolidering_BioStatHome/Documents/")
source("functions.R")
# Parametre -------------------------------------------------------------------------------------------------------
n <- 1e4                                                  # Antal obs
lambda <- 3e-4                                            # Konstant baseline hazard
HR <- 1                                                   # HR af behandling
HRsex <- 2
# tau <- rexp(n, rate=1/1000)                               # Censorering
## tau <- 1000
# lambdaPois <- 3                                           # Parameter til poissonfordeling
D <- 100                                                  # Behandlingslængde
M <- 4
# W <- rpois(n, lambda = lambdaPois) + 1                         # Antal behandlinger
sex <- rbinom(n, 1, .5)
W <- rpois(n, lambda = 2) + 1
W[sex == 1] <- rpois(sum(sex == 1), lambda = 3) + 1
# W <- sample(1:4, n, replace = TRUE, prob = c(.1,.2,.2,.5))
# W[sex == 1] <- rpois(sum(sex == 1), lambda = 2) + 1
UW <- (W == 1) + 2 * (W == 2) + 3 * (W == 3) + 4 * (W >= 4)    # HR for forskellige antal behandlinger
W <- rpois(n, lambda = 3.5) + 1
W[sex == 1] <- rpois(sum(sex == 1), lambda = 1.5) + 1
# W <- rpois(n, lambda = lambdaPois) + 1                         # Antal behandlinger
sex <- rbinom(n, 1, .5)
W <- rpois(n, lambda = 3.5) + 1
W[sex == 1] <- rpois(sum(sex == 1), lambda = 1.5) + 1
# W <- sample(1:4, n, replace = TRUE, prob = c(.1,.2,.2,.5))
# W[sex == 1] <- rpois(sum(sex == 1), lambda = 2) + 1
UW <- (W == 1) + 2 * (W == 2) + 3 * (W == 3) + 4 * (W >= 4)    # HR for forskellige antal behandlinger
# UW <- pmin(exp(W - 4), 1)
u <- runif(n)
br <- 1 - exp(-lambda * W * D * UW * HR * HRsex^sex)
X <- numeric(n)
X[u < br] <- -log(1 - u[u < br]) / (lambda * HR * UW[u < br] * HRsex^sex[u < br])
X[u >= br] <- (-log(1 - u[u >= br]) + lambda * UW[u >= br] * HRsex^sex[u >= br] * W[u >= br] * D * (1 - HR)) /
(lambda * UW[u >= br] * HRsex^sex[u >= br])
# tau <- rexp(n, rate=1/1000)                               # Censorering
tau <- 1000
# tau <- runif(n, 0, 1000)                                       # Censorering
T <- pmin(X, tau)
status <- as.numeric(X <= tau)
mean(status)
# Parametre -------------------------------------------------------------------------------------------------------
n <- 1e4                                                  # Antal obs
lambda <- 3e-4                                            # Konstant baseline hazard
HR <- 1                                                   # HR af behandling
HRsex <- 2
# tau <- rexp(n, rate=1/1000)                               # Censorering
tau <- 1000
# lambdaPois <- 3                                           # Parameter til poissonfordeling
D <- 100                                                  # Behandlingslængde
M <- 4
# W <- rpois(n, lambda = lambdaPois) + 1                         # Antal behandlinger
sex <- rbinom(n, 1, .5)
W <- rpois(n, lambda = 3.5) + 1
W[sex == 1] <- rpois(sum(sex == 1), lambda = 1.5) + 1
# W <- sample(1:4, n, replace = TRUE, prob = c(.1,.2,.2,.5))
# W[sex == 1] <- rpois(sum(sex == 1), lambda = 2) + 1
UW <- (W == 1) + 2 * (W == 2) + 3 * (W == 3) + 4 * (W >= 4)    # HR for forskellige antal behandlinger
# UW <- pmin(exp(W - 4), 1)
u <- runif(n)
br <- 1 - exp(-lambda * W * D * UW * HR * HRsex^sex)
X <- numeric(n)
X[u < br] <- -log(1 - u[u < br]) / (lambda * HR * UW[u < br] * HRsex^sex[u < br])
X[u >= br] <- (-log(1 - u[u >= br]) + lambda * UW[u >= br] * HRsex^sex[u >= br] * W[u >= br] * D * (1 - HR)) /
(lambda * UW[u >= br] * HRsex^sex[u >= br])
# tau <- runif(n, 0, 1000)                                       # Censorering
T <- pmin(X, tau)
status <- as.numeric(X <= tau)
obsW <- pmin(W, ceiling(T / D))                                # Vi observerer ikke W for alle
treat <- as.numeric(T <= (D * W))                              # Behandling eller ej ved event tidspunkt
statusW <- 1-treat                                             # Fortæller os om vi observerer W
mean(status)
